{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{MTCS-203(P): Topics in Database Management Systems}$\n",
    "### $\\text{Summative Test}$\n",
    "*By:<br>Shiva Krishna<br>I M.Tech.(CS)<br>Regd no: 22555*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.isfile('./input/query.txt'):\n",
    "#     os.system('gedit ./input/query.txt')\n",
    "if os.path.isfile('./output/output.csv'):\n",
    "    os.remove('./output/output.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Processing...\n"
     ]
    }
   ],
   "source": [
    "query = open(\"./input/query.txt\",\"r\")   # open the file with query\n",
    "char_replace={'Natural Join':'N_J', \n",
    "              'ORDER BY':'O_B',\n",
    "              ',':' '}\n",
    "line = []                     # lines in the query\n",
    "for l in query:                 # append all the lines form the query to the list 'line'\n",
    "    for key,value in char_replace.items():\n",
    "        l = l.replace(key,value)\n",
    "    line.append(l.split())\n",
    "\n",
    "print(\"\\nQuery Processing...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORDER BY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_by(ln):\n",
    "    o_df = pd.read_csv('./where.csv')\n",
    "    if ln[1] not in o_df.columns:\n",
    "        return \"Wrong attribute in the ORDER BY clause.\"\n",
    "\n",
    "    \n",
    "    if ((len(ln)==3) and (ln[2] == 'ASC')) or (len(ln)==2):\n",
    "        o_df.sort_values(by=ln[1], inplace = True, ascending=True)\n",
    "        o_df.to_csv('order.csv',index=False)\n",
    "    elif ((len(ln)==3) and (ln[2] == 'DESC')): \n",
    "        o_df.sort_values(by=ln[1], inplace = True, ascending=False)\n",
    "        o_df.to_csv('./order.csv',index=False)\n",
    "    return 'order.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where(ln):\n",
    "    df = pd.read_csv('./join.csv')\n",
    "    attr = ln[1]\n",
    "    val = ln[3]\n",
    "\n",
    "    if attr not in list(df.columns):\n",
    "        return \"Check your WHERE clause...\"\n",
    "    if attr in df.columns:\n",
    "        condition = ln[2]\n",
    "        if df.dtypes[attr] == object:\n",
    "            val = ln[3]\n",
    "        elif df.dtypes[attr] == int:\n",
    "            val = int(ln[3])\n",
    "        elif df.dtypes[attr] == float:\n",
    "            val = float(ln[3])\n",
    "        else:\n",
    "            return \"not a defined data type\"\n",
    "\n",
    "        new_df = pd.DataFrame(columns = list(df.columns),index = range(df.shape[0]))\n",
    "        rows = df.shape[0]\n",
    "        k,i=0,0\n",
    "        if condition == '=':\n",
    "            for i in range(rows):\n",
    "                if df.loc[i,attr] == val:\n",
    "                    new_df.loc[k] = list(df.loc[i])\n",
    "                    k+=1\n",
    "        elif condition == '>=':\n",
    "            for i in range(rows):\n",
    "                if df.loc[i,attr] >= val:\n",
    "                    new_df.loc[k] = list(df.loc[i])\n",
    "                    k+=1\n",
    "        elif condition == '>':\n",
    "            for i in range(rows):\n",
    "                if df.loc[i,attr] > val:\n",
    "                    new_df.loc[k] = list(df.loc[i])\n",
    "                    k+=1\n",
    "        elif condition == '<=':\n",
    "            for i in range(rows):\n",
    "                if df.loc[i,attr] <= val:\n",
    "                    new_df.loc[k] = list(df.loc[i])\n",
    "                    k+=1\n",
    "        else:\n",
    "            for i in range(rows):\n",
    "                if df.loc[i,attr] < val:\n",
    "                    new_df.loc[k] = list(df.loc[i])\n",
    "                    k+=1        \n",
    "        new_df.drop(range(k,df.shape[0]),inplace=True)\n",
    "        new_df.to_csv('./where.csv',columns = list(df.columns),index=False)\n",
    "        return 'where.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartesian Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_join(table_1,table_2):\n",
    "    intersect = []\n",
    "\n",
    "    columns_1 = []\n",
    "    columns_2 = []\n",
    "    for ats_1 in list(table_1.columns):\n",
    "        ats_1 = ats_1.replace(' ','')\n",
    "        columns_1.append(ats_1)\n",
    "    for ats_2 in list(table_2.columns):\n",
    "        ats_2 = ats_2.replace(' ','')\n",
    "        columns_2.append(ats_2)\n",
    "    table_1.columns = columns_1\n",
    "    table_2.columns = columns_2\n",
    "\n",
    "    for att in list(table_1.columns):\n",
    "        if att in list(table_2.columns):\n",
    "            intersect.append(att)\n",
    "    \n",
    "    flag = False\n",
    "    all_attr = (list(line[1][1][:-3]+table_1.columns)) + (list(line[1][2][:-3]+table_2.columns))\n",
    "    for i in range(len(line)):\n",
    "        for j in range(len(line[i])):\n",
    "            if line[i][j] in all_attr:\n",
    "                flag = True\n",
    "                break\n",
    "            else:\n",
    "                flag = False\n",
    "        if flag == True:\n",
    "            break    \n",
    "        \n",
    "    if (len(intersect)!=0) or (flag == True):   \n",
    "        new_tab = pd.DataFrame(columns = all_attr ,index = range(table_1.shape[0]*table_2.shape[0]))\n",
    "    else:    \n",
    "        new_tab = pd.DataFrame(columns = list(table_1.columns)+list(table_2.columns),index = range(table_1.shape[0]*table_2.shape[0]))\n",
    "   \n",
    "    k=0\n",
    "    for i in range(table_1.shape[0]):\n",
    "        for j in range(table_2.shape[0]):\n",
    "            new_tab.loc[k] = list(table_1.loc[i]) + list(table_2.loc[j])\n",
    "            k+=1\n",
    "    \n",
    "    new_tab.to_csv('join.csv',index=False)\n",
    "    return \"join.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_join(table_1,table_2):\n",
    "    intersect = []\n",
    "\n",
    "    columns_1 = []\n",
    "    columns_2 = []\n",
    "    for ats_1 in list(table_1.columns):\n",
    "        ats_1 = ats_1.replace(' ','')\n",
    "        columns_1.append(ats_1)\n",
    "    for ats_2 in list(table_2.columns):\n",
    "        ats_2 = ats_2.replace(' ','')\n",
    "        columns_2.append(ats_2)\n",
    "    table_1.columns = columns_1\n",
    "    table_2.columns = columns_2\n",
    "   \n",
    "    for att in list(table_1.columns):\n",
    "        if att in list(table_2.columns):\n",
    "            intersect.append(att)\n",
    "\n",
    "    if (len(intersect)==0):\n",
    "        return cartesian_join(table_1,table_2)\n",
    "\n",
    "    else:        \n",
    "        table_2.drop(intersect,axis=1).to_csv('after_drop.csv',index=False)\n",
    "        table_3 = pd.read_csv('./after_drop.csv')\n",
    "        all_attr = (list(line[1][1][:-3]+table_1.columns)) + (list(line[1][3][:-3]+table_3.columns))\n",
    "        \n",
    "        flag = False\n",
    "        for i in range(len(line)):\n",
    "            for j in range(len(line[i])):\n",
    "                if line[i][j] in all_attr:\n",
    "                    flag = True\n",
    "                    break\n",
    "                else:\n",
    "                    flag = False\n",
    "            if flag == True:\n",
    "                break \n",
    "        if flag == True:        \n",
    "            new_tab = pd.DataFrame(columns = all_attr,index = range(table_1.shape[0]*table_3.shape[0]))\n",
    "        else:\n",
    "            new_tab = pd.DataFrame(columns = list(table_1.columns)+list(table_3.columns),index = range(table_1.shape[0]*table_3.shape[0]))\n",
    "\n",
    "        for att in line[0][1:]:\n",
    "            if att not in list(new_tab.columns)+['*']:\n",
    "                return \"Give the correct attributes\"\n",
    "\n",
    "        k=0\n",
    "        for i in range(table_1.shape[0]):\n",
    "            for j in range(table_2.shape[0]):\n",
    "                if set(table_1.loc[i,intersect]) == set(table_2.loc[j,intersect]):    \n",
    "                    new_tab.loc[k] = (list(table_1.loc[i]) + list(table_3.loc[j]))\n",
    "                    k+=1\n",
    "        new_tab.drop(range(k,table_1.shape[0]*table_3.shape[0]),axis=0,inplace=True)\n",
    "        \n",
    "        os.remove(\"after_drop.csv\")\n",
    "        new_tab.to_csv('join.csv',index=False)\n",
    "    return \"join.csv\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_file(params_2):\n",
    "\n",
    "    if((len(params_2)==1) and (params_2[0][-4:]=='.csv')):\n",
    "        return params_2[0]\n",
    "    \n",
    "    if(len(params_2)>1):\n",
    "        if \"N_J\" not in params_2:\n",
    "            params_2[0] = cartesian_join(pd.read_csv('./datasets/'+params_2[0]),pd.read_csv('./datasets/'+params_2[1]))\n",
    "        else:\n",
    "            params_2[0] = natural_join(pd.read_csv('./datasets/'+params_2[0]),pd.read_csv('./datasets/'+params_2[2]))\n",
    "        return params_2[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(params_1):\n",
    "    table = ''\n",
    "    if params_1[0].upper() == 'FROM':\n",
    "        table = from_file(params_1[1:])\n",
    "    \n",
    "    if (len(line)>2) and line[2][0].upper() == 'WHERE' and os.path.isfile('./join.csv'):\n",
    "        table = where(line[2])\n",
    "    \n",
    "    if (len(line)>3) and line[3][0] == 'O_B' and os.path.isfile('./where.csv'):     # O_B == ORDER BY\n",
    "        table = order_by(line[3])\n",
    "    \n",
    "\n",
    "    if table!='.csv' and os.path.isfile(table):\n",
    "        df = pd.read_csv(table)\n",
    "        if (line[0][1]==\"*\"):\n",
    "            df.to_csv('./output/output.csv',index=False)\n",
    "        else:\n",
    "            df.to_csv('./output/output.csv',columns=line[0][1:],index=False)\n",
    "    else:\n",
    "        print(table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(params_1):\n",
    "    from_table = ''\n",
    "    where_table = ''\n",
    "    \n",
    "    if params_1[0].upper() == 'FROM':\n",
    "        from_table = from_file(params_1[1:])    # operation  \n",
    "        if len(params_1)>2:  \n",
    "            ft = pd.read_csv(from_table)\n",
    "        else:\n",
    "            ft = pd.read_csv(\"./datasets/\"+from_table)\n",
    "            ft.to_csv(\"./join.csv\",columns=ft.columns,index=False)\n",
    "            ft = pd.read_csv(\"./join.csv\")\n",
    "        delete_table = ft.drop(range(0,ft.shape[0]),axis=0)\n",
    "\n",
    "    if (len(line)>2) and line[2][0].upper() == 'WHERE' and (os.path.isfile(\"./\"+from_table) or os.path.isfile(\"./datasets/\"+from_table)):\n",
    "        where_table = where(line[2])\n",
    "        wt = pd.read_csv(where_table)\n",
    "        delete_table= pd.concat([wt,ft]).drop_duplicates(keep=False)\n",
    "\n",
    "    delete_table.to_csv('./output/output.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def limit(num):\n",
    "    lim_out = pd.read_csv('./output/output.csv')\n",
    "    if int(num) < lim_out.shape[0]:\n",
    "        new_out = lim_out.iloc[:int(num)]\n",
    "    else:\n",
    "        new_out = lim_out\n",
    "    new_out.to_csv('./output/output.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if line[0][0].upper() == 'SELECT':\n",
    "        select(line[1])\n",
    "    elif line[0][0].upper() == 'DELETE':\n",
    "        delete(line[1])\n",
    "        \n",
    "    if line[-1][0].upper() == 'LIMIT':\n",
    "        limit(line[-1][1])\n",
    "        \n",
    "    # if os.path.isfile('./join.csv'):\n",
    "    #     os.remove('join.csv')\n",
    "    # if os.path.isfile('./where.csv'):\n",
    "    #     os.remove('where.csv')\n",
    "    # if os.path.isfile('./order.csv'):\n",
    "    #     os.remove('order.csv')\n",
    "    if os.path.isfile('./output/output.csv'):\n",
    "        print(\"Output\")\n",
    "        os.system('code ./output/output.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
